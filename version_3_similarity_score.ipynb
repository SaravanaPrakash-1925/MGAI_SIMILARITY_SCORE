{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DHFBqZ5Ql5wk",
    "outputId": "896bb047-6cd2-4f5e-e17c-4c41b0df9b31"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: librosa in /home/ubuntu/.local/lib/python3.10/site-packages (0.10.2.post1)\n",
      "Requirement already satisfied: numpy in /home/ubuntu/.local/lib/python3.10/site-packages (1.26.4)\n",
      "Requirement already satisfied: faiss-cpu in /home/ubuntu/.local/lib/python3.10/site-packages (1.10.0)\n",
      "Requirement already satisfied: torch in /home/ubuntu/.local/lib/python3.10/site-packages (2.1.0)\n",
      "Requirement already satisfied: transformers in /home/ubuntu/.local/lib/python3.10/site-packages (4.49.0)\n",
      "Requirement already satisfied: crepe in /home/ubuntu/.local/lib/python3.10/site-packages (0.0.16)\n",
      "Requirement already satisfied: scipy in /home/ubuntu/.local/lib/python3.10/site-packages (1.15.2)\n",
      "Requirement already satisfied: fastdtw in /home/ubuntu/.local/lib/python3.10/site-packages (0.3.4)\n",
      "Requirement already satisfied: tqdm in /home/ubuntu/.local/lib/python3.10/site-packages (4.67.1)\n",
      "Requirement already satisfied: nnAudio in /home/ubuntu/.local/lib/python3.10/site-packages (0.3.3)\n",
      "Requirement already satisfied: jsonlines in /home/ubuntu/.local/lib/python3.10/site-packages (4.0.0)\n",
      "Requirement already satisfied: audioread>=2.1.9 in /home/ubuntu/.local/lib/python3.10/site-packages (from librosa) (3.0.1)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from librosa) (1.6.1)\n",
      "Requirement already satisfied: joblib>=0.14 in /home/ubuntu/.local/lib/python3.10/site-packages (from librosa) (1.4.2)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /usr/lib/python3/dist-packages (from librosa) (4.4.2)\n",
      "Requirement already satisfied: numba>=0.51.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from librosa) (0.58.1)\n",
      "Requirement already satisfied: soundfile>=0.12.1 in /home/ubuntu/.local/lib/python3.10/site-packages (from librosa) (0.13.1)\n",
      "Requirement already satisfied: pooch>=1.1 in /home/ubuntu/.local/lib/python3.10/site-packages (from librosa) (1.8.2)\n",
      "Requirement already satisfied: soxr>=0.3.2 in /home/ubuntu/.local/lib/python3.10/site-packages (from librosa) (0.5.0.post1)\n",
      "Requirement already satisfied: typing-extensions>=4.1.1 in /home/ubuntu/.local/lib/python3.10/site-packages (from librosa) (4.14.1)\n",
      "Requirement already satisfied: lazy-loader>=0.1 in /home/ubuntu/.local/lib/python3.10/site-packages (from librosa) (0.4)\n",
      "Requirement already satisfied: msgpack>=1.0 in /usr/lib/python3/dist-packages (from librosa) (1.0.3)\n",
      "Requirement already satisfied: packaging in /home/ubuntu/.local/lib/python3.10/site-packages (from faiss-cpu) (25.0)\n",
      "Requirement already satisfied: filelock in /home/ubuntu/.local/lib/python3.10/site-packages (from torch) (3.17.0)\n",
      "Requirement already satisfied: sympy in /home/ubuntu/.local/lib/python3.10/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: networkx in /home/ubuntu/.local/lib/python3.10/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /home/ubuntu/.local/lib/python3.10/site-packages (from torch) (3.1.5)\n",
      "Requirement already satisfied: fsspec in /home/ubuntu/.local/lib/python3.10/site-packages (from torch) (2024.9.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/ubuntu/.local/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/ubuntu/.local/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/ubuntu/.local/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/ubuntu/.local/lib/python3.10/site-packages (from torch) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/ubuntu/.local/lib/python3.10/site-packages (from torch) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/ubuntu/.local/lib/python3.10/site-packages (from torch) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/ubuntu/.local/lib/python3.10/site-packages (from torch) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/ubuntu/.local/lib/python3.10/site-packages (from torch) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/ubuntu/.local/lib/python3.10/site-packages (from torch) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /home/ubuntu/.local/lib/python3.10/site-packages (from torch) (2.18.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/ubuntu/.local/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: triton==2.1.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from torch) (2.1.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/ubuntu/.local/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.4.127)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from transformers) (0.28.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ubuntu/.local/lib/python3.10/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/ubuntu/.local/lib/python3.10/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /home/ubuntu/.local/lib/python3.10/site-packages (from transformers) (2.32.4)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /home/ubuntu/.local/lib/python3.10/site-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/ubuntu/.local/lib/python3.10/site-packages (from transformers) (0.5.2)\n",
      "Requirement already satisfied: h5py in /usr/lib/python3/dist-packages (from crepe) (3.6.0)\n",
      "Requirement already satisfied: hmmlearn>=0.3.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from crepe) (0.3.3)\n",
      "Requirement already satisfied: imageio>=2.3.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from crepe) (2.37.0)\n",
      "Requirement already satisfied: matplotlib>=2.1.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from crepe) (3.10.1)\n",
      "Requirement already satisfied: resampy>=0.2.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from crepe) (0.2.2)\n",
      "Requirement already satisfied: attrs>=19.2.0 in /usr/lib/python3/dist-packages (from jsonlines) (21.2.0)\n",
      "Requirement already satisfied: pillow>=8.3.2 in /home/ubuntu/.local/lib/python3.10/site-packages (from imageio>=2.3.0->crepe) (10.4.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/ubuntu/.local/lib/python3.10/site-packages (from matplotlib>=2.1.0->crepe) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/ubuntu/.local/lib/python3.10/site-packages (from matplotlib>=2.1.0->crepe) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from matplotlib>=2.1.0->crepe) (4.55.8)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/ubuntu/.local/lib/python3.10/site-packages (from matplotlib>=2.1.0->crepe) (1.4.8)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/ubuntu/.local/lib/python3.10/site-packages (from matplotlib>=2.1.0->crepe) (3.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/ubuntu/.local/lib/python3.10/site-packages (from matplotlib>=2.1.0->crepe) (2.9.0.post0)\n",
      "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /home/ubuntu/.local/lib/python3.10/site-packages (from numba>=0.51.0->librosa) (0.41.1)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from pooch>=1.1->librosa) (4.3.8)\n",
      "Requirement already satisfied: six>=1.5 in /home/ubuntu/.local/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib>=2.1.0->crepe) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/ubuntu/.local/lib/python3.10/site-packages (from requests->transformers) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ubuntu/.local/lib/python3.10/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ubuntu/.local/lib/python3.10/site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ubuntu/.local/lib/python3.10/site-packages (from requests->transformers) (2025.8.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from scikit-learn>=0.20.0->librosa) (3.5.0)\n",
      "Requirement already satisfied: cffi>=1.0 in /usr/lib/python3/dist-packages (from soundfile>=0.12.1->librosa) (1.15.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n",
      "\u001b[33mWARNING: Error parsing dependencies of flatbuffers: Invalid version: '1.12.1-git20200711.33e2d80-dfsg1-0.6'\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install librosa numpy faiss-cpu torch transformers crepe scipy fastdtw tqdm nnAudio jsonlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "8v06XHtUYOx7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-21 11:42:08,511 - WARNING - Feature files missing in /home/ubuntu/mahesh_YUE/version_3_embed: ['embeddings.npy', 'spectral.npy', 'chroma_seq.npy', 'onsets.npy', 'tempos.npy', 'melody_sequences.npy', 'lyrics_emb.npy', 'chord_seq.npy', 'rms.npy', 'tracks.npy', 'max_distance_onsets.npy', 'max_distance_chroma.npy', 'max_distance_rms.npy']\n",
      "I0000 00:00:1755776534.238803 3412442 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 46866 MB memory:  -> device: 0, name: NVIDIA RTX A6000, pci bus id: 0000:07:00.0, compute capability: 8.6\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1755776537.274022 3412533 service.cc:148] XLA service 0x7bbd4400d950 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1755776537.274122 3412533 service.cc:156]   StreamExecutor device (0): NVIDIA RTX A6000, Compute Capability 8.6\n",
      "2025-08-21 11:42:17.312370: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1755776537.388550 3412533 cuda_dnn.cc:529] Loaded cuDNN version 90501\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 39/606\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 4ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1755776538.226373 3412527 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m556/556\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step\n",
      "\u001b[1m606/606\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step\n",
      "\u001b[1m1067/1067\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step\n",
      "\u001b[1m1156/1156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing audio files: 100%|██████████| 5/5 [01:13<00:00, 14.65s/it]\n",
      "2025-08-21 11:43:22,084 - INFO - Successfully saved features to /home/ubuntu/mahesh_YUE/version_3_embed with 5 tracks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1067/1067\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-21 11:43:45,135 - INFO - Dynamic weights: {'H': 0.04419216267009347, 'M': 0.19399517334478447, 'B': 0.13246047427704927, 'C': 0.14123041224982508, 'S': 0.04626186156810752, 'T': 0.10460655194051856, 'L': 0.1271769222357077, 'Chord': 0.10768433818796548, 'E': 0.10239209569259557}\n",
      "2025-08-21 11:43:45,137 - INFO - Variances: {'H': 0.1364888, 'M': 0.1497899508659471, 'B': 0.13636935800373912, 'C': 0.1090485713996631, 'S': 0.14288112125219268, 'T': 0.16154020747287498, 'L': 0.1309298893336354, 'Chord': 0.11086208279034335, 'E': 0.1317670840156806}\n",
      "2025-08-21 11:43:45,137 - INFO - Top 20 tracks: ['KISS - Crazy Crazy Nights.mp3', 'Aerosmith - Dude (Looks Like A Lady).mp3', 'The Beatles - All My Loving - Remastered 2009.mp3', 'Lita Ford - Playin_ with Fire.mp3', 'light-instrumental-melody-4-319030.wav']\n",
      "2025-08-21 11:43:45,139 - INFO - Query audio KISS - Crazy Crazy Nights.mp3 found with score 0.991\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top similar tracks:\n",
      "Track: KISS - Crazy Crazy Nights.mp3, Score: 0.991\n",
      "Track: Aerosmith - Dude (Looks Like A Lady).mp3, Score: 0.452\n",
      "Track: The Beatles - All My Loving - Remastered 2009.mp3, Score: 0.342\n",
      "Track: Lita Ford - Playin_ with Fire.mp3, Score: 0.339\n",
      "Track: light-instrumental-melody-4-319030.wav, Score: 0.193\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "import faiss\n",
    "import logging\n",
    "import torch\n",
    "from transformers import ClapProcessor, ClapModel, WhisperProcessor, WhisperForConditionalGeneration, BertTokenizer, BertModel\n",
    "import crepe\n",
    "from scipy.signal import butter, filtfilt\n",
    "from scipy.spatial.distance import cosine\n",
    "from fastdtw import fastdtw\n",
    "from tqdm import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import random\n",
    "from scipy.signal import correlate\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# CLAP model setup (fallback)\n",
    "# Note: To use MERT instead, replace with from transformers import AutoProcessor, AutoModel; processor = AutoProcessor.from_pretrained(\"m-a-p/MERT-v1-95M\"); model = AutoModel.from_pretrained(\"m-a-p/MERT-v1-95M\")\n",
    "# Then adjust extract_clap_embedding to use model.encode_audio or similar.\n",
    "embedding_dim = 512\n",
    "index = faiss.IndexFlatL2(embedding_dim)\n",
    "processor = ClapProcessor.from_pretrained(\"laion/clap-htsat-unfused\")\n",
    "model = ClapModel.from_pretrained(\"laion/clap-htsat-unfused\")\n",
    "\n",
    "# Whisper for lyrics (upgraded to medium for better accuracy)\n",
    "whisper_processor = WhisperProcessor.from_pretrained(\"openai/whisper-medium\")\n",
    "whisper_model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-medium\")\n",
    "\n",
    "# BERT for lyrics embeddings\n",
    "bert_tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "bert_model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# Database storage\n",
    "database_embeddings = []\n",
    "database_spectral = []\n",
    "database_chroma_seq = []\n",
    "database_onsets = []\n",
    "database_tempos = []\n",
    "database_melody_sequences = []\n",
    "database_lyrics_emb = []\n",
    "database_chord_seq = []\n",
    "database_rms = []  # New for RMS energy sequences\n",
    "database_tracks = []\n",
    "\n",
    "# Paths and constants\n",
    "AUDIO_FOLDER_PATH = \"/home/ubuntu/mahesh_YUE/input_songs1\"\n",
    "EMBEDDINGS_DIR = \"/home/ubuntu/mahesh_YUE/version_3_embed\"\n",
    "ALLOWED_FORMATS = ('.mp3', '.wav', '.aiff')\n",
    "\n",
    "# Low-pass filter\n",
    "def lowpass_filter(signal, sr, cutoff=2500):\n",
    "    nyquist = 0.5 * sr\n",
    "    norm_cutoff = cutoff / nyquist\n",
    "    b, a = butter(4, norm_cutoff, btype='low', analog=False)\n",
    "    return filtfilt(b, a, signal)\n",
    "\n",
    "# Feature extraction\n",
    "def extract_clap_embedding(audio, sr=48000):\n",
    "    try:\n",
    "        inputs = processor(audios=[audio], sampling_rate=sr, return_tensors=\"pt\", padding=True)\n",
    "        with torch.no_grad():\n",
    "            embedding = model.get_audio_features(**inputs)\n",
    "        return np.array(embedding.squeeze().numpy(), dtype=np.float32)\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error extracting CLAP embedding: {e}\")\n",
    "        return None\n",
    "\n",
    "def extract_lyrics_embedding(audio, sr):\n",
    "    try:\n",
    "        audio_16k = librosa.resample(audio, orig_sr=sr, target_sr=16000)\n",
    "        input_features = whisper_processor(audio_16k, sampling_rate=16000, return_tensors=\"pt\").input_features\n",
    "        predicted_ids = whisper_model.generate(input_features)\n",
    "        lyrics = whisper_processor.batch_decode(predicted_ids, skip_special_tokens=True)[0]\n",
    "        inputs = bert_tokenizer(lyrics, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "        with torch.no_grad():\n",
    "            outputs = bert_model(**inputs)\n",
    "        emb = outputs.pooler_output.squeeze().numpy().astype(np.float32)\n",
    "        return emb\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error extracting lyrics: {e}\")\n",
    "        return None\n",
    "\n",
    "def extract_melody_sequence(audio, sr=16000):\n",
    "    try:\n",
    "        mono = librosa.to_mono(audio) if audio.ndim > 1 else audio\n",
    "        filtered = lowpass_filter(mono, sr)\n",
    "        time, frequency, confidence, _ = crepe.predict(filtered, sr, model_capacity='tiny', step_size=20)\n",
    "        high_conf_idx = confidence > 0.7\n",
    "        if not np.any(high_conf_idx):\n",
    "            return None\n",
    "        freqs = frequency[high_conf_idx].astype(np.float32)\n",
    "        log_freqs = np.log2(freqs / 440) * 1200  # Cents for shift invariance\n",
    "        return log_freqs\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error extracting melody: {e}\")\n",
    "        return None\n",
    "\n",
    "def extract_spectral_features(audio, sr):\n",
    "    try:\n",
    "        mfccs = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=13)\n",
    "        return np.mean(mfccs, axis=1).astype(np.float32)\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error extracting spectral features: {e}\")\n",
    "        return None\n",
    "\n",
    "def extract_chroma_features(audio, sr, beats):\n",
    "    try:\n",
    "        chroma = librosa.feature.chroma_cqt(y=audio, sr=sr, bins_per_octave=48)  # Higher resolution\n",
    "        if beats is None:\n",
    "            return None\n",
    "        synced_chroma = librosa.util.sync(chroma, beats, aggregate=np.mean)\n",
    "        return synced_chroma.T.astype(np.float32)\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error extracting chroma features: {e}\")\n",
    "        return None\n",
    "\n",
    "def extract_chord_sequence(audio, sr, beats):\n",
    "    try:\n",
    "        chroma = librosa.feature.chroma_cqt(y=audio, sr=sr)\n",
    "        chords = librosa.effects.harmonic(chroma)  # Simplified harmonic extraction\n",
    "        synced_chords = librosa.util.sync(chords, beats, aggregate=np.mean)\n",
    "        return synced_chords.T.astype(np.float32)\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error extracting chord sequence: {e}\")\n",
    "        return None\n",
    "\n",
    "def extract_rms_sequence(audio, sr, beats):\n",
    "    try:\n",
    "        rms = librosa.feature.rms(y=audio)\n",
    "        if beats is None:\n",
    "            return None\n",
    "        synced_rms = librosa.util.sync(rms, beats, aggregate=np.mean)\n",
    "        return synced_rms.flatten().astype(np.float32)\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error extracting RMS sequence: {e}\")\n",
    "        return None\n",
    "\n",
    "def extract_onset_features(audio, sr):\n",
    "    try:\n",
    "        onset_env = librosa.onset.onset_strength(y=audio, sr=sr)\n",
    "        tempo, beats = librosa.beat.beat_track(onset_envelope=onset_env, sr=sr)\n",
    "        onset_frames = librosa.frames_to_samples(beats, hop_length=512)\n",
    "        tempo_scalar = float(tempo) if np.isscalar(tempo) else float(tempo[0])\n",
    "        return onset_env[:len(onset_frames)], tempo_scalar, beats\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error extracting onset features: {e}\")\n",
    "        return None, None, None\n",
    "\n",
    "def process_audio_file(audio_path):\n",
    "    try:\n",
    "        y, sr = librosa.load(audio_path, sr=None)\n",
    "        y = librosa.util.normalize(y)  # Normalize audio volume\n",
    "        onsets, tempo, beats = extract_onset_features(y, sr)\n",
    "        rms = extract_rms_sequence(y, sr, beats)\n",
    "        return audio_path, (\n",
    "            extract_clap_embedding(y),\n",
    "            extract_spectral_features(y, sr),\n",
    "            extract_chroma_features(y, sr, beats),\n",
    "            onsets,\n",
    "            tempo,\n",
    "            extract_melody_sequence(y),\n",
    "            extract_lyrics_embedding(y, sr),\n",
    "            extract_chord_sequence(y, sr, beats),\n",
    "            rms  # New\n",
    "        )\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error processing {audio_path}: {e}\")\n",
    "        return audio_path, (None, None, None, None, None, None, None, None, None)\n",
    "\n",
    "# Distance and similarity functions\n",
    "def scalar_distance(x, y):\n",
    "    return abs(x - y)\n",
    "\n",
    "def dtw_similarity(seq1, seq2, sigma, dist_func=scalar_distance):\n",
    "    if seq1 is None or seq2 is None or len(seq1) < 2 or len(seq2) < 2:\n",
    "        return 0.0\n",
    "    try:\n",
    "        downsample_rate = max(1, len(seq1) // 5000)\n",
    "        seq1_ds = seq1[::downsample_rate]\n",
    "        seq2_ds = seq2[::downsample_rate]\n",
    "        if dist_func == cosine:  # For chroma/chords\n",
    "            mean1 = np.mean(seq1_ds, axis=0)\n",
    "            mean2 = np.mean(seq2_ds, axis=0)\n",
    "            corr = [np.dot(np.roll(mean1, k), mean2) for k in range(12)]\n",
    "            best_shift = np.argmax(corr)\n",
    "            seq2_ds = np.roll(seq2_ds, best_shift, axis=1)\n",
    "        if dist_func == scalar_distance:  # For melody\n",
    "            seq1_diff = np.diff(seq1_ds)\n",
    "            seq2_diff = np.diff(seq2_ds)\n",
    "            dtw_distance, path = fastdtw(seq1_diff, seq2_diff, dist=dist_func)\n",
    "            dtw_distance /= len(path) if path else 1  # Local alignment norm\n",
    "        else:\n",
    "            dtw_distance, path = fastdtw(seq1_ds, seq2_ds, dist=dist_func)\n",
    "            dtw_distance /= len(path) if path else 1\n",
    "        return np.exp(-dtw_distance / sigma)\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in DTW computation: {e}\")\n",
    "        return 0.0\n",
    "\n",
    "# Save features\n",
    "def save_features():\n",
    "    try:\n",
    "        os.makedirs(EMBEDDINGS_DIR, exist_ok=True)\n",
    "        if not os.access(EMBEDDINGS_DIR, os.W_OK):\n",
    "            raise PermissionError(f\"No write permission for {EMBEDDINGS_DIR}\")\n",
    "        if not database_tracks:\n",
    "            logger.warning(\"No valid tracks to save\")\n",
    "            return False\n",
    "        np.save(os.path.join(EMBEDDINGS_DIR, \"embeddings.npy\"), np.array(database_embeddings, dtype=np.float32))\n",
    "        np.save(os.path.join(EMBEDDINGS_DIR, \"spectral.npy\"), np.array(database_spectral, dtype=np.float32))\n",
    "        np.save(os.path.join(EMBEDDINGS_DIR, \"chroma_seq.npy\"), np.array(database_chroma_seq, dtype=object))\n",
    "        np.save(os.path.join(EMBEDDINGS_DIR, \"onsets.npy\"), np.array(database_onsets, dtype=object))\n",
    "        np.save(os.path.join(EMBEDDINGS_DIR, \"tempos.npy\"), np.array(database_tempos, dtype=np.float32))\n",
    "        np.save(os.path.join(EMBEDDINGS_DIR, \"melody_sequences.npy\"), np.array(database_melody_sequences, dtype=object))\n",
    "        np.save(os.path.join(EMBEDDINGS_DIR, \"lyrics_emb.npy\"), np.array(database_lyrics_emb, dtype=np.float32))\n",
    "        np.save(os.path.join(EMBEDDINGS_DIR, \"chord_seq.npy\"), np.array(database_chord_seq, dtype=object))\n",
    "        np.save(os.path.join(EMBEDDINGS_DIR, \"rms.npy\"), np.array(database_rms, dtype=object))  # New\n",
    "        np.save(os.path.join(EMBEDDINGS_DIR, \"tracks.npy\"), np.array(database_tracks, dtype=str))\n",
    "        np.save(os.path.join(EMBEDDINGS_DIR, \"max_distance_onsets.npy\"), np.array([MAX_DISTANCE_ONSETS], dtype=np.float32))\n",
    "        np.save(os.path.join(EMBEDDINGS_DIR, \"max_distance_chroma.npy\"), np.array([MAX_DISTANCE_CHROMA], dtype=np.float32))\n",
    "        np.save(os.path.join(EMBEDDINGS_DIR, \"max_distance_rms.npy\"), np.array([MAX_DISTANCE_RMS], dtype=np.float32))  # New\n",
    "        logger.info(f\"Successfully saved features to {EMBEDDINGS_DIR} with {len(database_tracks)} tracks\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to save features: {e}\")\n",
    "        return False\n",
    "\n",
    "# Load features\n",
    "def load_features():\n",
    "    global database_embeddings, database_spectral, database_chroma_seq, database_onsets, database_tempos, database_melody_sequences, database_lyrics_emb, database_chord_seq, database_rms, database_tracks, MAX_DISTANCE_ONSETS, MAX_DISTANCE_CHROMA, MAX_DISTANCE_RMS\n",
    "    required_files = [\"embeddings.npy\", \"spectral.npy\", \"chroma_seq.npy\", \"onsets.npy\", \"tempos.npy\", \"melody_sequences.npy\", \"lyrics_emb.npy\", \"chord_seq.npy\", \"rms.npy\", \"tracks.npy\", \"max_distance_onsets.npy\", \"max_distance_chroma.npy\", \"max_distance_rms.npy\"]\n",
    "    if os.path.exists(EMBEDDINGS_DIR) and all(os.path.exists(os.path.join(EMBEDDINGS_DIR, f)) for f in required_files):\n",
    "        try:\n",
    "            database_embeddings = np.load(os.path.join(EMBEDDINGS_DIR, \"embeddings.npy\")).tolist()\n",
    "            database_spectral = np.load(os.path.join(EMBEDDINGS_DIR, \"spectral.npy\")).tolist()\n",
    "            database_chroma_seq = np.load(os.path.join(EMBEDDINGS_DIR, \"chroma_seq.npy\"), allow_pickle=True).tolist()\n",
    "            database_onsets = np.load(os.path.join(EMBEDDINGS_DIR, \"onsets.npy\"), allow_pickle=True).tolist()\n",
    "            database_tempos = np.load(os.path.join(EMBEDDINGS_DIR, \"tempos.npy\")).tolist()\n",
    "            database_melody_sequences = np.load(os.path.join(EMBEDDINGS_DIR, \"melody_sequences.npy\"), allow_pickle=True).tolist()\n",
    "            database_lyrics_emb = np.load(os.path.join(EMBEDDINGS_DIR, \"lyrics_emb.npy\")).tolist()\n",
    "            database_chord_seq = np.load(os.path.join(EMBEDDINGS_DIR, \"chord_seq.npy\"), allow_pickle=True).tolist()\n",
    "            database_rms = np.load(os.path.join(EMBEDDINGS_DIR, \"rms.npy\"), allow_pickle=True).tolist()  # New\n",
    "            database_tracks = np.load(os.path.join(EMBEDDINGS_DIR, \"tracks.npy\")).tolist()\n",
    "            MAX_DISTANCE_ONSETS = np.load(os.path.join(EMBEDDINGS_DIR, \"max_distance_onsets.npy\"))[0]\n",
    "            MAX_DISTANCE_CHROMA = np.load(os.path.join(EMBEDDINGS_DIR, \"max_distance_chroma.npy\"))[0]\n",
    "            MAX_DISTANCE_RMS = np.load(os.path.join(EMBEDDINGS_DIR, \"max_distance_rms.npy\"))[0]  # New\n",
    "            index.reset()\n",
    "            index.add(np.array(database_embeddings, dtype=np.float32))\n",
    "            logger.info(f\"Successfully loaded features from {EMBEDDINGS_DIR} with {len(database_tracks)} tracks\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error loading features: {e}\")\n",
    "            return False\n",
    "    else:\n",
    "        missing_files = [f for f in required_files if not os.path.exists(os.path.join(EMBEDDINGS_DIR, f))]\n",
    "        logger.warning(f\"Feature files missing in {EMBEDDINGS_DIR}: {missing_files}\")\n",
    "        return False\n",
    "\n",
    "# Database initialization\n",
    "def initialize_database():\n",
    "    global MAX_DISTANCE_ONSETS, MAX_DISTANCE_CHROMA, MAX_DISTANCE_RMS\n",
    "    if load_features():\n",
    "        return\n",
    "    audio_files = [os.path.join(AUDIO_FOLDER_PATH, f) for f in os.listdir(AUDIO_FOLDER_PATH) if f.endswith(ALLOWED_FORMATS)]\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        results = list(tqdm(executor.map(process_audio_file, audio_files), total=len(audio_files), desc=\"Processing audio files\"))\n",
    "    for audio_path, result in results:\n",
    "        if all(v is not None for v in result):\n",
    "            database_embeddings.append(result[0])\n",
    "            database_spectral.append(result[1])\n",
    "            database_chroma_seq.append(result[2])\n",
    "            database_onsets.append(result[3])\n",
    "            database_tempos.append(result[4])\n",
    "            database_melody_sequences.append(result[5])\n",
    "            database_lyrics_emb.append(result[6])\n",
    "            database_chord_seq.append(result[7])\n",
    "            database_rms.append(result[8])  # New\n",
    "            database_tracks.append(os.path.basename(audio_path))\n",
    "    n = len(database_onsets)\n",
    "    all_pairs = [(i, j) for i in range(n) for j in range(i + 1, n)]\n",
    "    sample_size = min(100, len(all_pairs))\n",
    "    sampled_pairs = random.sample(all_pairs, sample_size) if sample_size < len(all_pairs) else all_pairs\n",
    "    onset_dtw_distances = []\n",
    "    for i, j in sampled_pairs:\n",
    "        if database_onsets[i] is not None and database_onsets[j] is not None:\n",
    "            dist, _ = fastdtw(database_onsets[i][::5], database_onsets[j][::5], dist=scalar_distance)\n",
    "            onset_dtw_distances.append(dist)\n",
    "    MAX_DISTANCE_ONSETS = max(onset_dtw_distances) if onset_dtw_distances else 1000\n",
    "    chroma_dtw_distances = []\n",
    "    chroma_dist = lambda x, y: cosine(x, y)\n",
    "    for i, j in sampled_pairs:\n",
    "        if database_chroma_seq[i] is not None and database_chroma_seq[j] is not None:\n",
    "            dist, _ = fastdtw(database_chroma_seq[i][::5], database_chroma_seq[j][::5], dist=chroma_dist)\n",
    "            chroma_dtw_distances.append(dist)\n",
    "    MAX_DISTANCE_CHROMA = max(chroma_dtw_distances) if chroma_dtw_distances else 1000\n",
    "    rms_dtw_distances = []\n",
    "    for i, j in sampled_pairs:\n",
    "        if database_rms[i] is not None and database_rms[j] is not None:\n",
    "            dist, _ = fastdtw(database_rms[i][::5], database_rms[j][::5], dist=scalar_distance)\n",
    "            rms_dtw_distances.append(dist)\n",
    "    MAX_DISTANCE_RMS = max(rms_dtw_distances) if rms_dtw_distances else 1.0  # RMS is typically small\n",
    "    if database_embeddings:\n",
    "        index.add(np.array(database_embeddings, dtype=np.float32))\n",
    "        save_features()\n",
    "    else:\n",
    "        logger.warning(\"Database is empty!\")\n",
    "\n",
    "# Query comparison\n",
    "def compare_query_to_database(query_audio_path):\n",
    "    y, sr = librosa.load(query_audio_path, sr=None)\n",
    "    y = librosa.util.normalize(y)  # Normalize audio volume\n",
    "    onsets, tempo, beats = extract_onset_features(y, sr)\n",
    "    query_clap = extract_clap_embedding(y)\n",
    "    query_spectral = extract_spectral_features(y, sr)\n",
    "    query_chroma_seq = extract_chroma_features(y, sr, beats)\n",
    "    query_onsets = onsets\n",
    "    query_tempo = tempo\n",
    "    query_melody_seq = extract_melody_sequence(y)\n",
    "    query_lyrics_emb = extract_lyrics_embedding(y, sr)\n",
    "    query_chord_seq = extract_chord_sequence(y, sr, beats)\n",
    "    query_rms = extract_rms_sequence(y, sr, beats)\n",
    "    if query_clap is not None:\n",
    "        query_clap_reshaped = query_clap.reshape(1, -1)\n",
    "        k = min(100, len(database_embeddings))\n",
    "        D, I = index.search(query_clap_reshaped, k)\n",
    "        candidates = [int(idx) for idx in I[0] if idx != -1]\n",
    "    else:\n",
    "        candidates = list(range(len(database_embeddings)))\n",
    "    H_list, M_list, B_list, C_list, S_list, T_list, L_list, Chord_list, E_list = [], [], [], [], [], [], [], [], []\n",
    "    chroma_dist = lambda x, y: cosine(x, y)\n",
    "    for i in candidates:\n",
    "        H = np.dot(query_clap, database_embeddings[i]) / (np.linalg.norm(query_clap) * np.linalg.norm(database_embeddings[i])) if query_clap is not None else 0.0\n",
    "        H = max(0, H)\n",
    "        S = 1 - cosine(query_spectral, database_spectral[i]) if query_spectral is not None else 0.0\n",
    "        S = max(0, S)\n",
    "        C = dtw_similarity(query_chroma_seq, database_chroma_seq[i], sigma=MAX_DISTANCE_CHROMA / 10, dist_func=chroma_dist)\n",
    "        B = dtw_similarity(query_onsets, database_onsets[i], sigma=MAX_DISTANCE_ONSETS / 10)\n",
    "        M = dtw_similarity(query_melody_seq, database_melody_sequences[i], sigma=50)\n",
    "        T = np.exp(-abs(query_tempo - database_tempos[i]) / 10) if query_tempo is not None else 0.0\n",
    "        L = 1 - cosine(query_lyrics_emb, database_lyrics_emb[i]) if query_lyrics_emb is not None else 0.0\n",
    "        L = max(0, L)\n",
    "        Chord = dtw_similarity(query_chord_seq, database_chord_seq[i], sigma=MAX_DISTANCE_CHROMA / 10, dist_func=chroma_dist)\n",
    "        E = dtw_similarity(query_rms, database_rms[i], sigma=MAX_DISTANCE_RMS / 10, dist_func=scalar_distance)\n",
    "        H_list.append(H)\n",
    "        S_list.append(S)\n",
    "        C_list.append(C)\n",
    "        B_list.append(B)\n",
    "        M_list.append(M)\n",
    "        T_list.append(T)\n",
    "        L_list.append(L)\n",
    "        Chord_list.append(Chord)\n",
    "        E_list.append(E)\n",
    "    def normalize(lst):\n",
    "        lst = np.array(lst)\n",
    "        min_val, max_val = lst.min(), lst.max()\n",
    "        return (lst - min_val) / (max_val - min_val + 1e-8) if max_val > min_val else lst / (lst + 1e-8)\n",
    "    H_list = normalize(H_list)\n",
    "    M_list = normalize(M_list)\n",
    "    B_list = normalize(B_list)\n",
    "    C_list = normalize(C_list)\n",
    "    S_list = normalize(S_list)\n",
    "    T_list = normalize(T_list)\n",
    "    L_list = normalize(L_list)\n",
    "    Chord_list = normalize(Chord_list)\n",
    "    E_list = normalize(E_list)\n",
    "    variances = {\n",
    "        'H': np.var(H_list),\n",
    "        'M': np.var(M_list),\n",
    "        'B': np.var(B_list),\n",
    "        'C': np.var(C_list),\n",
    "        'S': np.var(S_list),\n",
    "        'T': np.var(T_list),\n",
    "        'L': np.var(L_list),\n",
    "        'Chord': np.var(Chord_list),\n",
    "        'E': np.var(E_list)\n",
    "    }\n",
    "    adjusted_weights = {f: variances[f] for f in variances}\n",
    "    total_weight = sum(adjusted_weights.values()) + 1e-8\n",
    "    adjusted_weights = {f: w / total_weight for f, w in adjusted_weights.items()}\n",
    "    adjusted_weights['M'] *= 2.0\n",
    "    adjusted_weights['C'] *= 2.0\n",
    "    adjusted_weights['B'] *= 1.5\n",
    "    adjusted_weights['L'] *= 1.5\n",
    "    adjusted_weights['Chord'] *= 1.5\n",
    "    adjusted_weights['E'] *= 1.2  # New for energy\n",
    "    adjusted_weights['S'] *= 0.5\n",
    "    adjusted_weights['H'] *= 0.5\n",
    "    total_weight = sum(adjusted_weights.values()) + 1e-8\n",
    "    adjusted_weights = {f: w / total_weight for f, w in adjusted_weights.items()}\n",
    "    logger.info(f\"Dynamic weights: {adjusted_weights}\")\n",
    "    logger.info(f\"Variances: {variances}\")\n",
    "    similarities = []\n",
    "    for idx, i in enumerate(candidates):\n",
    "        score = (\n",
    "            adjusted_weights['H'] * H_list[idx] +\n",
    "            adjusted_weights['M'] * M_list[idx] +\n",
    "            adjusted_weights['B'] * B_list[idx] +\n",
    "            adjusted_weights['C'] * C_list[idx] +\n",
    "            adjusted_weights['S'] * S_list[idx] +\n",
    "            adjusted_weights['T'] * T_list[idx] +\n",
    "            adjusted_weights['L'] * L_list[idx] +\n",
    "            adjusted_weights['Chord'] * Chord_list[idx] +\n",
    "            adjusted_weights['E'] * E_list[idx]\n",
    "        )\n",
    "        similarities.append({'track': database_tracks[i], 'similarity_score': score})\n",
    "    similarities.sort(key=lambda x: x['similarity_score'], reverse=True)\n",
    "    top_20 = similarities[:20]\n",
    "    logger.info(f\"Top 20 tracks: {[t['track'] for t in top_20]}\")\n",
    "    return top_20\n",
    "\n",
    "# Main execution\n",
    "def main():\n",
    "    initialize_database()\n",
    "    if not database_embeddings:\n",
    "        logger.warning(\"No valid audio data available.\")\n",
    "        return\n",
    "    query_audio = \"/home/ubuntu/mahesh_YUE/input_songs1/KISS - Crazy Crazy Nights.mp3\"\n",
    "    top_similar = compare_query_to_database(query_audio)\n",
    "    print(\"\\nTop similar tracks:\")\n",
    "    query_filename = os.path.basename(query_audio)\n",
    "    for t in top_similar:\n",
    "        print(f\"Track: {t['track']}, Score: {t['similarity_score']:.3f}\")\n",
    "        if t['track'] == query_filename:\n",
    "            logger.info(f\"Query audio {query_filename} found with score {t['similarity_score']:.3f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jDoYlD9iqPJd"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sgAmWWZtqPM_"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zIm2gQBeZjKe"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Sk1aILk0ZjNU"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r54OFwHka6Uv"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
