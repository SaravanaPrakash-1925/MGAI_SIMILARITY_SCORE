{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "X2UgEwYwCf99"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-21 11:53:48,193 - INFO - Successfully loaded features from /home/ubuntu/mahesh_YUE/music_similarity_embeddings/genrewise1/lofi with 177 tracks\n",
      "2025-08-21 11:53:48,194 - INFO - Loaded MAX_DISTANCE_ONSETS: 71.14161682128906\n",
      "I0000 00:00:1755777230.930685 3412980 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1030 MB memory:  -> device: 0, name: NVIDIA RTX A6000, pci bus id: 0000:07:00.0, compute capability: 8.6\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1755777232.113785 3413172 service.cc:148] XLA service 0x7c67ac003fd0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1755777232.113868 3413172 service.cc:156]   StreamExecutor device (0): NVIDIA RTX A6000, Compute Capability 8.6\n",
      "2025-08-21 11:53:52.139208: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1755777232.193696 3413172 cuda_dnn.cc:529] Loaded cuDNN version 90501\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 60/130\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step    "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1755777232.867670 3413172 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-21 11:53:55,017 - INFO - Dynamic weights: {'H': 0.11507052389472819, 'M': 0.029641170207862784, 'B': 0.2067701882614766, 'C': 0.08402225247675282, 'S': 0.1200334440474605, 'T': 0.44446236834870795}\n",
      "2025-08-21 11:53:55,018 - INFO - Variances: {'H': 0.021808937957094796, 'M': 0.005617793507487299, 'B': 0.03918847376845869, 'C': 0.01592446118484047, 'S': 0.02274954389190373, 'T': 0.08423749095335847}\n",
      "2025-08-21 11:53:55,019 - INFO - Top 20 tracks: ['aunt - Ocean Ride.mp3', 'Casiio - Central Park.mp3', 'Cmd q - Morse.mp3', 'aroramo - machine.mp3', 'Vincent Rayn - Birds Eye.mp3', 'parrow - Pink.mp3', 'Justnormal - Fika.mp3', 'galaxx - Lazy Streets.mp3', 'Domo 759 - Meantime.mp3', 'Dryden - Summer Memories.mp3', 'Jost Esser - lemon soda.mp3', 'Erwin Do - Fragments.mp3', 'Tojié Cai - Niwa.mp3', 'Summer Clarke - devotion.mp3', 'MODALiST - Jouissance.mp3', 'Lownas - Spirit.mp3', 'Phresh Milk - no way but up.mp3', 'rocomoco - Aurola - Inf & Rainn Remix.mp3', 'morningtime - headway.mp3', 'C4C - Call a Friend.mp3']\n",
      "2025-08-21 11:53:55,021 - INFO - Query audio aunt - Ocean Ride.mp3 found with score 1.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top similar tracks:\n",
      "Track: aunt - Ocean Ride.mp3, Score: 1.000\n",
      "Track: Casiio - Central Park.mp3, Score: 0.834\n",
      "Track: Cmd q - Morse.mp3, Score: 0.825\n",
      "Track: aroramo - machine.mp3, Score: 0.816\n",
      "Track: Vincent Rayn - Birds Eye.mp3, Score: 0.803\n",
      "Track: parrow - Pink.mp3, Score: 0.796\n",
      "Track: Justnormal - Fika.mp3, Score: 0.780\n",
      "Track: galaxx - Lazy Streets.mp3, Score: 0.769\n",
      "Track: Domo 759 - Meantime.mp3, Score: 0.748\n",
      "Track: Dryden - Summer Memories.mp3, Score: 0.746\n",
      "Track: Jost Esser - lemon soda.mp3, Score: 0.731\n",
      "Track: Erwin Do - Fragments.mp3, Score: 0.723\n",
      "Track: Tojié Cai - Niwa.mp3, Score: 0.666\n",
      "Track: Summer Clarke - devotion.mp3, Score: 0.666\n",
      "Track: MODALiST - Jouissance.mp3, Score: 0.664\n",
      "Track: Lownas - Spirit.mp3, Score: 0.653\n",
      "Track: Phresh Milk - no way but up.mp3, Score: 0.649\n",
      "Track: rocomoco - Aurola - Inf & Rainn Remix.mp3, Score: 0.620\n",
      "Track: morningtime - headway.mp3, Score: 0.619\n",
      "Track: C4C - Call a Friend.mp3, Score: 0.615\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "import faiss\n",
    "import logging\n",
    "import torch\n",
    "from transformers import ClapProcessor, ClapModel\n",
    "import crepe\n",
    "from scipy.signal import butter, filtfilt\n",
    "from scipy.spatial.distance import cosine\n",
    "from fastdtw import fastdtw\n",
    "from tqdm import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# CLAP model setup\n",
    "embedding_dim = 512\n",
    "index = faiss.IndexFlatL2(embedding_dim)\n",
    "processor = ClapProcessor.from_pretrained(\"laion/clap-htsat-unfused\")\n",
    "model = ClapModel.from_pretrained(\"laion/clap-htsat-unfused\")\n",
    "\n",
    "# Database storage\n",
    "database_embeddings = []\n",
    "database_spectral = []\n",
    "database_chroma = []\n",
    "database_onsets = []\n",
    "database_tempos = []\n",
    "database_melody_sequences = []\n",
    "database_tracks = []\n",
    "\n",
    "# Paths and constants\n",
    "AUDIO_FOLDER_PATH = \"/home/ubuntu/mahesh_YUE/Finetuned_songs/ambient\"  # <-- Your input directory\n",
    "EMBEDDINGS_DIR = \"/home/ubuntu/mahesh_YUE/music_similarity_embeddings/genrewise1/lofi\"\n",
    "ALLOWED_FORMATS = ('.mp3', '.wav', '.aiff')\n",
    "\n",
    "# Low-pass filter for melody SWB filtering\n",
    "def lowpass_filter(signal, sr, cutoff=2500):\n",
    "    nyquist = 0.5 * sr\n",
    "    norm_cutoff = cutoff / nyquist\n",
    "    b, a = butter(4, norm_cutoff, btype='low', analog=False)\n",
    "    return filtfilt(b, a, signal)\n",
    "\n",
    "# Feature extraction functions\n",
    "def extract_clap_embedding(audio, sr=48000):\n",
    "    try:\n",
    "        inputs = processor(audios=[audio], sampling_rate=sr, return_tensors=\"pt\", padding=True)\n",
    "        with torch.no_grad():\n",
    "            embedding = model.get_audio_features(**inputs)\n",
    "        return np.array(embedding.squeeze().numpy(), dtype=np.float32)\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error extracting CLAP embedding: {e}\")\n",
    "        return None\n",
    "\n",
    "def extract_melody_sequence(audio, sr=16000):\n",
    "    try:\n",
    "        mono = librosa.to_mono(audio) if audio.ndim > 1 else audio\n",
    "        filtered = lowpass_filter(mono, sr)\n",
    "        time, frequency, confidence, _ = crepe.predict(filtered, sr, model_capacity='tiny', step_size=20)\n",
    "        high_conf_idx = confidence > 0.7\n",
    "        if not np.any(high_conf_idx):\n",
    "            return None\n",
    "        return frequency[high_conf_idx].astype(np.float32)\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error extracting melody: {e}\")\n",
    "        return None\n",
    "\n",
    "def extract_spectral_features(audio, sr):\n",
    "    try:\n",
    "        mfccs = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=13)\n",
    "        return np.mean(mfccs, axis=1).astype(np.float32)\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error extracting spectral features: {e}\")\n",
    "        return None\n",
    "\n",
    "def extract_chroma_features(audio, sr):\n",
    "    try:\n",
    "        chroma = librosa.feature.chroma_stft(y=audio, sr=sr)\n",
    "        return np.mean(chroma, axis=1).astype(np.float32)\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error extracting chroma features: {e}\")\n",
    "        return None\n",
    "\n",
    "def extract_onset_features(audio, sr):\n",
    "    try:\n",
    "        onset_env = librosa.onset.onset_strength(y=audio, sr=sr)\n",
    "        tempo, beats = librosa.beat.beat_track(onset_envelope=onset_env, sr=sr)\n",
    "        onset_frames = librosa.frames_to_samples(beats, hop_length=512)\n",
    "        tempo_scalar = float(tempo) if np.isscalar(tempo) else float(tempo[0])\n",
    "        return onset_env[:len(onset_frames)], tempo_scalar\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error extracting onset features: {e}\")\n",
    "        return None, None\n",
    "\n",
    "def process_audio_file(audio_path):\n",
    "    try:\n",
    "        y, sr = librosa.load(audio_path, sr=None, duration=30.0)\n",
    "        return audio_path, (\n",
    "            extract_clap_embedding(y),\n",
    "            extract_spectral_features(y, sr),\n",
    "            extract_chroma_features(y, sr),\n",
    "            extract_onset_features(y, sr)[0],\n",
    "            extract_onset_features(y, sr)[1],\n",
    "            extract_melody_sequence(y)\n",
    "        )\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error processing {audio_path}: {e}\")\n",
    "        return audio_path, (None, None, None, None, None, None)\n",
    "\n",
    "# Distance and similarity functions\n",
    "def scalar_distance(x, y):\n",
    "    return abs(x - y)\n",
    "\n",
    "def dtw_similarity(seq1, seq2, sigma):\n",
    "    if seq1 is None or seq2 is None or len(seq1) < 2 or len(seq2) < 2:\n",
    "        return 0.0\n",
    "    try:\n",
    "        seq1_ds = seq1[::2]\n",
    "        seq2_ds = seq2[::2]\n",
    "        dtw_distance, _ = fastdtw(seq1_ds, seq2_ds, dist=scalar_distance)\n",
    "        return np.exp(-dtw_distance / sigma)\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in DTW computation: {e}\")\n",
    "        return 0.0\n",
    "\n",
    "# Save features\n",
    "def save_features():\n",
    "    try:\n",
    "        os.makedirs(EMBEDDINGS_DIR, exist_ok=True)\n",
    "        if not os.access(EMBEDDINGS_DIR, os.W_OK):\n",
    "            logger.error(f\"No write permission for {EMBEDDINGS_DIR}\")\n",
    "            raise PermissionError(f\"No write permission for {EMBEDDINGS_DIR}\")\n",
    "\n",
    "        if not database_tracks:\n",
    "            logger.warning(\"No valid tracks to save\")\n",
    "            return False\n",
    "\n",
    "        np.save(os.path.join(EMBEDDINGS_DIR, \"embeddings.npy\"), np.array(database_embeddings, dtype=np.float32))\n",
    "        np.save(os.path.join(EMBEDDINGS_DIR, \"spectral.npy\"), np.array(database_spectral, dtype=np.float32))\n",
    "        np.save(os.path.join(EMBEDDINGS_DIR, \"chroma.npy\"), np.array(database_chroma, dtype=np.float32))\n",
    "        np.save(os.path.join(EMBEDDINGS_DIR, \"onsets.npy\"), np.array(database_onsets, dtype=object))\n",
    "        np.save(os.path.join(EMBEDDINGS_DIR, \"tempos.npy\"), np.array(database_tempos, dtype=np.float32))\n",
    "        np.save(os.path.join(EMBEDDINGS_DIR, \"melody_sequences.npy\"), np.array(database_melody_sequences, dtype=object))\n",
    "        np.save(os.path.join(EMBEDDINGS_DIR, \"tracks.npy\"), np.array(database_tracks, dtype=str))\n",
    "        np.save(os.path.join(EMBEDDINGS_DIR, \"max_distance_onsets.npy\"), np.array([MAX_DISTANCE_ONSETS], dtype=np.float32))\n",
    "        logger.info(f\"Successfully saved features to {EMBEDDINGS_DIR} with {len(database_tracks)} tracks\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to save features: {e}\")\n",
    "        return False\n",
    "\n",
    "# Load features\n",
    "def load_features():\n",
    "    global database_embeddings, database_spectral, database_chroma, database_onsets, database_tempos, database_melody_sequences, database_tracks, MAX_DISTANCE_ONSETS\n",
    "    required_files = [\"embeddings.npy\", \"spectral.npy\", \"chroma.npy\", \"onsets.npy\", \"tempos.npy\", \"melody_sequences.npy\", \"tracks.npy\", \"max_distance_onsets.npy\"]\n",
    "\n",
    "    if os.path.exists(EMBEDDINGS_DIR) and all(os.path.exists(os.path.join(EMBEDDINGS_DIR, f)) for f in required_files):\n",
    "        try:\n",
    "            database_embeddings = np.load(os.path.join(EMBEDDINGS_DIR, \"embeddings.npy\")).tolist()\n",
    "            database_spectral = np.load(os.path.join(EMBEDDINGS_DIR, \"spectral.npy\")).tolist()\n",
    "            database_chroma = np.load(os.path.join(EMBEDDINGS_DIR, \"chroma.npy\")).tolist()\n",
    "            database_onsets = np.load(os.path.join(EMBEDDINGS_DIR, \"onsets.npy\"), allow_pickle=True).tolist()\n",
    "            database_tempos = np.load(os.path.join(EMBEDDINGS_DIR, \"tempos.npy\")).tolist()\n",
    "            database_melody_sequences = np.load(os.path.join(EMBEDDINGS_DIR, \"melody_sequences.npy\"), allow_pickle=True).tolist()\n",
    "            database_tracks = np.load(os.path.join(EMBEDDINGS_DIR, \"tracks.npy\")).tolist()\n",
    "            MAX_DISTANCE_ONSETS = np.load(os.path.join(EMBEDDINGS_DIR, \"max_distance_onsets.npy\"))[0]\n",
    "\n",
    "            index.reset()\n",
    "            index.add(np.array(database_embeddings, dtype=np.float32))\n",
    "            logger.info(f\"Successfully loaded features from {EMBEDDINGS_DIR} with {len(database_tracks)} tracks\")\n",
    "            logger.info(f\"Loaded MAX_DISTANCE_ONSETS: {MAX_DISTANCE_ONSETS}\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error loading features: {e}\")\n",
    "            return False\n",
    "    else:\n",
    "        missing_files = [f for f in required_files if not os.path.exists(os.path.join(EMBEDDINGS_DIR, f))]\n",
    "        logger.warning(f\"Feature files missing in {EMBEDDINGS_DIR}: {missing_files}\")\n",
    "        return False\n",
    "\n",
    "# Database initialization\n",
    "def initialize_database():\n",
    "    global MAX_DISTANCE_ONSETS\n",
    "    # Check if features are already saved\n",
    "    if load_features():\n",
    "        return\n",
    "\n",
    "    # If features don't exist, extract and save them\n",
    "    audio_files = [os.path.join(AUDIO_FOLDER_PATH, f) for f in os.listdir(AUDIO_FOLDER_PATH) if f.endswith(ALLOWED_FORMATS)]\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        results = list(tqdm(executor.map(process_audio_file, audio_files), total=len(audio_files), desc=\"Processing audio files\"))\n",
    "\n",
    "    for audio_path, result in results:\n",
    "        if all(v is not None for v in result):\n",
    "            database_embeddings.append(result[0])\n",
    "            database_spectral.append(result[1])\n",
    "            database_chroma.append(result[2])\n",
    "            database_onsets.append(result[3])\n",
    "            database_tempos.append(result[4])\n",
    "            database_melody_sequences.append(result[5])\n",
    "            database_tracks.append(os.path.basename(audio_path))\n",
    "\n",
    "    onset_dtw_distances = []\n",
    "    for i in range(len(database_onsets)):\n",
    "        for j in range(i + 1, len(database_onsets)):\n",
    "            if database_onsets[i] is not None and database_onsets[j] is not None:\n",
    "                dist, _ = fastdtw(database_onsets[i][::2], database_onsets[j][::2], dist=scalar_distance)\n",
    "                onset_dtw_distances.append(dist)\n",
    "    MAX_DISTANCE_ONSETS = max(onset_dtw_distances) if onset_dtw_distances else 1000\n",
    "    logger.info(f\"Dynamic MAX_DISTANCE_ONSETS: {MAX_DISTANCE_ONSETS}\")\n",
    "\n",
    "    if database_embeddings:\n",
    "        index.add(np.array(database_embeddings, dtype=np.float32))\n",
    "        logger.info(f\"Database initialized with {len(database_embeddings)} tracks\")\n",
    "        save_features()\n",
    "    else:\n",
    "        logger.warning(\"Database is empty!\")\n",
    "\n",
    "# Query comparison\n",
    "def compare_query_to_database(query_audio_path):\n",
    "    y, sr = librosa.load(query_audio_path, sr=None, duration=30.0)\n",
    "    query_clap = extract_clap_embedding(y)\n",
    "    query_spectral = extract_spectral_features(y, sr)\n",
    "    query_chroma = extract_chroma_features(y, sr)\n",
    "    query_onsets, query_tempo = extract_onset_features(y, sr)\n",
    "    query_melody_seq = extract_melody_sequence(y)\n",
    "\n",
    "    # Compute similarities\n",
    "    H_list, M_list, B_list, C_list, S_list, T_list = [], [], [], [], [], []\n",
    "    for i in range(len(database_embeddings)):\n",
    "        H = np.dot(query_clap, database_embeddings[i]) / (np.linalg.norm(query_clap) * np.linalg.norm(database_embeddings[i])) if query_clap is not None else 0.0\n",
    "        H = max(0, H)\n",
    "        S = 1 - cosine(query_spectral, database_spectral[i]) if query_spectral is not None else 0.0\n",
    "        S = max(0, S)\n",
    "        C = 1 - cosine(query_chroma, database_chroma[i]) if query_chroma is not None else 0.0\n",
    "        C = max(0, C)\n",
    "        B = dtw_similarity(query_onsets, database_onsets[i], sigma=MAX_DISTANCE_ONSETS / 10)\n",
    "        M = dtw_similarity(query_melody_seq, database_melody_sequences[i], sigma=50)\n",
    "        T = np.exp(-abs(query_tempo - database_tempos[i]) / 10) if query_tempo is not None else 0.0\n",
    "\n",
    "        H_list.append(H)\n",
    "        S_list.append(S)\n",
    "        C_list.append(C)\n",
    "        B_list.append(B)\n",
    "        M_list.append(M)\n",
    "        T_list.append(T)\n",
    "\n",
    "    # Normalize similarities to [0,1]\n",
    "    def normalize(lst):\n",
    "        lst = np.array(lst)\n",
    "        min_val, max_val = lst.min(), lst.max()\n",
    "        return (lst - min_val) / (max_val - min_val + 1e-8) if max_val > min_val else lst / (lst + 1e-8)\n",
    "\n",
    "    H_list = normalize(H_list)\n",
    "    M_list = normalize(M_list)\n",
    "    B_list = normalize(B_list)\n",
    "    C_list = normalize(C_list)\n",
    "    S_list = normalize(S_list)\n",
    "    T_list = normalize(T_list)\n",
    "\n",
    "    # Compute variances for dynamic weights\n",
    "    variances = {\n",
    "        'H': np.var(H_list),\n",
    "        'M': np.var(M_list),\n",
    "        'B': np.var(B_list),\n",
    "        'C': np.var(C_list),\n",
    "        'S': np.var(S_list),\n",
    "        'T': np.var(T_list)\n",
    "    }\n",
    "\n",
    "    # Dynamic weights based solely on variances\n",
    "    adjusted_weights = {f: variances[f] for f in variances}\n",
    "    total_weight = sum(adjusted_weights.values()) + 1e-8\n",
    "    adjusted_weights = {f: w / total_weight for f, w in adjusted_weights.items()}\n",
    "    logger.info(f\"Dynamic weights: {adjusted_weights}\")\n",
    "    logger.info(f\"Variances: {variances}\")\n",
    "\n",
    "    # Compute final scores using weighted sum\n",
    "    similarities = []\n",
    "    for i in range(len(database_tracks)):\n",
    "        score = (\n",
    "            adjusted_weights['H'] * H_list[i] +\n",
    "            adjusted_weights['M'] * M_list[i] +\n",
    "            adjusted_weights['B'] * B_list[i] +\n",
    "            adjusted_weights['C'] * C_list[i] +\n",
    "            adjusted_weights['S'] * S_list[i] +\n",
    "            adjusted_weights['T'] * T_list[i]\n",
    "        )\n",
    "        similarities.append({'track': database_tracks[i], 'similarity_score': score})\n",
    "\n",
    "    similarities.sort(key=lambda x: x['similarity_score'], reverse=True)\n",
    "    top_20 = similarities[:20]\n",
    "    logger.info(f\"Top 20 tracks: {[t['track'] for t in top_20]}\")\n",
    "    return top_20\n",
    "\n",
    "# Main execution\n",
    "def main():\n",
    "    initialize_database()\n",
    "    if not database_embeddings:\n",
    "        logger.warning(\"No valid audio data available.\")\n",
    "        return\n",
    "    query_audio = \"/home/ubuntu/mahesh_YUE/Finetuned_songs/lofi/aunt - Ocean Ride.mp3\"  # <-- Your query path (replace with a dataset song)\n",
    "    top_similar = compare_query_to_database(query_audio)\n",
    "    print(\"\\nTop similar tracks:\")\n",
    "    query_filename = os.path.basename(query_audio)\n",
    "    for t in top_similar:\n",
    "        print(f\"Track: {t['track']}, Score: {t['similarity_score']:.3f}\")\n",
    "        if t['track'] == query_filename:\n",
    "            logger.info(f\"Query audio {query_filename} found with score {t['similarity_score']:.3f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
