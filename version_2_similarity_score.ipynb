{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n5LHWL7oqN2m",
    "outputId": "010492fa-d0b8-4af4-9068-0d01ed248f35"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: librosa in /home/ubuntu/.local/lib/python3.10/site-packages (0.10.2.post1)\n",
      "Requirement already satisfied: numpy in /home/ubuntu/.local/lib/python3.10/site-packages (1.26.4)\n",
      "Requirement already satisfied: faiss-cpu in /home/ubuntu/.local/lib/python3.10/site-packages (1.10.0)\n",
      "Requirement already satisfied: torch in /home/ubuntu/.local/lib/python3.10/site-packages (2.1.0)\n",
      "Requirement already satisfied: transformers in /home/ubuntu/.local/lib/python3.10/site-packages (4.49.0)\n",
      "Requirement already satisfied: crepe in /home/ubuntu/.local/lib/python3.10/site-packages (0.0.16)\n",
      "Requirement already satisfied: scipy in /home/ubuntu/.local/lib/python3.10/site-packages (1.15.2)\n",
      "Requirement already satisfied: fastdtw in /home/ubuntu/.local/lib/python3.10/site-packages (0.3.4)\n",
      "Requirement already satisfied: tqdm in /home/ubuntu/.local/lib/python3.10/site-packages (4.67.1)\n",
      "Requirement already satisfied: nnAudio in /home/ubuntu/.local/lib/python3.10/site-packages (0.3.3)\n",
      "Requirement already satisfied: jsonlines in /home/ubuntu/.local/lib/python3.10/site-packages (4.0.0)\n",
      "Requirement already satisfied: audioread>=2.1.9 in /home/ubuntu/.local/lib/python3.10/site-packages (from librosa) (3.0.1)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from librosa) (1.6.1)\n",
      "Requirement already satisfied: joblib>=0.14 in /home/ubuntu/.local/lib/python3.10/site-packages (from librosa) (1.4.2)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /usr/lib/python3/dist-packages (from librosa) (4.4.2)\n",
      "Requirement already satisfied: numba>=0.51.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from librosa) (0.58.1)\n",
      "Requirement already satisfied: soundfile>=0.12.1 in /home/ubuntu/.local/lib/python3.10/site-packages (from librosa) (0.13.1)\n",
      "Requirement already satisfied: pooch>=1.1 in /home/ubuntu/.local/lib/python3.10/site-packages (from librosa) (1.8.2)\n",
      "Requirement already satisfied: soxr>=0.3.2 in /home/ubuntu/.local/lib/python3.10/site-packages (from librosa) (0.5.0.post1)\n",
      "Requirement already satisfied: typing-extensions>=4.1.1 in /home/ubuntu/.local/lib/python3.10/site-packages (from librosa) (4.14.1)\n",
      "Requirement already satisfied: lazy-loader>=0.1 in /home/ubuntu/.local/lib/python3.10/site-packages (from librosa) (0.4)\n",
      "Requirement already satisfied: msgpack>=1.0 in /usr/lib/python3/dist-packages (from librosa) (1.0.3)\n",
      "Requirement already satisfied: packaging in /home/ubuntu/.local/lib/python3.10/site-packages (from faiss-cpu) (25.0)\n",
      "Requirement already satisfied: filelock in /home/ubuntu/.local/lib/python3.10/site-packages (from torch) (3.17.0)\n",
      "Requirement already satisfied: sympy in /home/ubuntu/.local/lib/python3.10/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: networkx in /home/ubuntu/.local/lib/python3.10/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /home/ubuntu/.local/lib/python3.10/site-packages (from torch) (3.1.5)\n",
      "Requirement already satisfied: fsspec in /home/ubuntu/.local/lib/python3.10/site-packages (from torch) (2024.9.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/ubuntu/.local/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/ubuntu/.local/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/ubuntu/.local/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/ubuntu/.local/lib/python3.10/site-packages (from torch) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/ubuntu/.local/lib/python3.10/site-packages (from torch) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/ubuntu/.local/lib/python3.10/site-packages (from torch) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/ubuntu/.local/lib/python3.10/site-packages (from torch) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/ubuntu/.local/lib/python3.10/site-packages (from torch) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/ubuntu/.local/lib/python3.10/site-packages (from torch) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /home/ubuntu/.local/lib/python3.10/site-packages (from torch) (2.18.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/ubuntu/.local/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: triton==2.1.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from torch) (2.1.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/ubuntu/.local/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.4.127)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from transformers) (0.28.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ubuntu/.local/lib/python3.10/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/ubuntu/.local/lib/python3.10/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /home/ubuntu/.local/lib/python3.10/site-packages (from transformers) (2.32.4)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /home/ubuntu/.local/lib/python3.10/site-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/ubuntu/.local/lib/python3.10/site-packages (from transformers) (0.5.2)\n",
      "Requirement already satisfied: h5py in /usr/lib/python3/dist-packages (from crepe) (3.6.0)\n",
      "Requirement already satisfied: hmmlearn>=0.3.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from crepe) (0.3.3)\n",
      "Requirement already satisfied: imageio>=2.3.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from crepe) (2.37.0)\n",
      "Requirement already satisfied: matplotlib>=2.1.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from crepe) (3.10.1)\n",
      "Requirement already satisfied: resampy>=0.2.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from crepe) (0.2.2)\n",
      "Requirement already satisfied: attrs>=19.2.0 in /usr/lib/python3/dist-packages (from jsonlines) (21.2.0)\n",
      "Requirement already satisfied: pillow>=8.3.2 in /home/ubuntu/.local/lib/python3.10/site-packages (from imageio>=2.3.0->crepe) (10.4.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/ubuntu/.local/lib/python3.10/site-packages (from matplotlib>=2.1.0->crepe) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/ubuntu/.local/lib/python3.10/site-packages (from matplotlib>=2.1.0->crepe) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from matplotlib>=2.1.0->crepe) (4.55.8)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/ubuntu/.local/lib/python3.10/site-packages (from matplotlib>=2.1.0->crepe) (1.4.8)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/ubuntu/.local/lib/python3.10/site-packages (from matplotlib>=2.1.0->crepe) (3.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/ubuntu/.local/lib/python3.10/site-packages (from matplotlib>=2.1.0->crepe) (2.9.0.post0)\n",
      "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /home/ubuntu/.local/lib/python3.10/site-packages (from numba>=0.51.0->librosa) (0.41.1)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from pooch>=1.1->librosa) (4.3.8)\n",
      "Requirement already satisfied: six>=1.5 in /home/ubuntu/.local/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib>=2.1.0->crepe) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/ubuntu/.local/lib/python3.10/site-packages (from requests->transformers) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ubuntu/.local/lib/python3.10/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ubuntu/.local/lib/python3.10/site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ubuntu/.local/lib/python3.10/site-packages (from requests->transformers) (2025.8.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from scikit-learn>=0.20.0->librosa) (3.5.0)\n",
      "Requirement already satisfied: cffi>=1.0 in /usr/lib/python3/dist-packages (from soundfile>=0.12.1->librosa) (1.15.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n",
      "\u001b[33mWARNING: Error parsing dependencies of flatbuffers: Invalid version: '1.12.1-git20200711.33e2d80-dfsg1-0.6'\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install librosa numpy faiss-cpu torch transformers crepe scipy fastdtw tqdm nnAudio jsonlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6UA4PGlJ3rO7",
    "outputId": "fc71bea7-1b16-4caa-8ebd-31b6ea9310f3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-21 11:25:07,964 - INFO - Query duration: 30.00s, max amplitude: 1.0161\n",
      "2025-08-21 11:25:08,121 - INFO - Onsets detected: 12/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-21 11:25:08,997 - INFO - Embeddings created: 6\n",
      "2025-08-21 11:25:09,279 - INFO - Onsets detected: 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-21 11:25:10,136 - INFO - Embeddings created: 1\n",
      "2025-08-21 11:25:10,514 - INFO - Onsets detected: 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-21 11:25:11,423 - INFO - Embeddings created: 1\n",
      "2025-08-21 11:25:11,653 - INFO - Onsets detected: 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-21 11:25:12,458 - WARNING - No valid embeddings created.\n",
      "2025-08-21 11:25:12,791 - INFO - Onsets detected: 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-21 11:25:13,742 - INFO - Embeddings created: 1\n",
      "2025-08-21 11:25:13,790 - INFO - Onsets detected: 31\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-21 11:25:14,669 - INFO - Embeddings created: 23\n",
      "2025-08-21 11:25:14,739 - INFO - Onsets detected: 54\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-21 11:25:15,650 - INFO - Embeddings created: 32\n",
      "2025-08-21 11:25:15,652 - INFO - Processed The Beatles - All My Loving - Remastered 2009.mp3: 3 variants\n",
      "2025-08-21 11:25:15,755 - INFO - Onsets detected: 52  7.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-21 11:25:16,630 - INFO - Embeddings created: 31\n",
      "2025-08-21 11:25:16,912 - INFO - Onsets detected: 28\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-21 11:25:17,774 - INFO - Embeddings created: 16\n",
      "2025-08-21 11:25:18,011 - INFO - Onsets detected: 24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-21 11:25:18,919 - INFO - Embeddings created: 12\n",
      "2025-08-21 11:25:19,151 - INFO - Onsets detected: 25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-21 11:25:19,953 - INFO - Embeddings created: 16\n",
      "2025-08-21 11:25:20,224 - INFO - Onsets detected: 28\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-21 11:25:21,209 - INFO - Embeddings created: 17\n",
      "2025-08-21 11:25:21,294 - INFO - Onsets detected: 55\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-21 11:25:22,200 - INFO - Embeddings created: 33\n",
      "2025-08-21 11:25:22,272 - INFO - Onsets detected: 51\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-21 11:25:23,219 - INFO - Embeddings created: 17\n",
      "2025-08-21 11:25:23,220 - INFO - Processed KISS - Crazy Crazy Nights.mp3: 7 variants\n",
      "2025-08-21 11:25:23,296 - INFO - Onsets detected: 109 7.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-21 11:25:24,158 - INFO - Embeddings created: 103\n",
      "2025-08-21 11:25:24,452 - INFO - Onsets detected: 65\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-21 11:25:25,310 - INFO - Embeddings created: 63\n",
      "2025-08-21 11:25:25,558 - INFO - Onsets detected: 18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-21 11:25:26,419 - INFO - Embeddings created: 14\n",
      "2025-08-21 11:25:26,661 - INFO - Onsets detected: 43\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-21 11:25:27,451 - INFO - Embeddings created: 43\n",
      "2025-08-21 11:25:27,757 - INFO - Onsets detected: 30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-21 11:25:28,700 - INFO - Embeddings created: 30\n",
      "2025-08-21 11:25:28,747 - INFO - Onsets detected: 108\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-21 11:25:29,629 - INFO - Embeddings created: 102\n",
      "2025-08-21 11:25:29,697 - INFO - Onsets detected: 104\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-21 11:25:30,599 - INFO - Embeddings created: 96\n",
      "2025-08-21 11:25:30,601 - INFO - Processed light-instrumental-melody-4-319030.wav: 7 variants\n",
      "2025-08-21 11:25:30,697 - INFO - Onsets detected: 12  7.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-21 11:25:31,576 - INFO - Embeddings created: 8\n",
      "2025-08-21 11:25:31,875 - INFO - Onsets detected: 1\n",
      "2025-08-21 11:25:31,877 - WARNING - Insufficient onsets detected (<2).\n",
      "2025-08-21 11:25:32,115 - INFO - Onsets detected: 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-21 11:25:32,989 - INFO - Embeddings created: 3\n",
      "2025-08-21 11:25:33,220 - INFO - Onsets detected: 1\n",
      "2025-08-21 11:25:33,222 - WARNING - Insufficient onsets detected (<2).\n",
      "2025-08-21 11:25:33,497 - INFO - Onsets detected: 1\n",
      "2025-08-21 11:25:33,498 - WARNING - Insufficient onsets detected (<2).\n",
      "2025-08-21 11:25:33,546 - INFO - Onsets detected: 29\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-21 11:25:34,438 - INFO - Embeddings created: 19\n",
      "2025-08-21 11:25:34,503 - INFO - Onsets detected: 67\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-21 11:25:35,386 - INFO - Embeddings created: 39\n",
      "2025-08-21 11:25:35,387 - INFO - Processed Lita Ford - Playin_ with Fire.mp3: 3 variants\n",
      "2025-08-21 11:25:35,478 - INFO - Onsets detected: 9,  6.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-21 11:25:36,348 - INFO - Embeddings created: 4\n",
      "2025-08-21 11:25:36,658 - INFO - Onsets detected: 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-21 11:25:37,516 - INFO - Embeddings created: 2\n",
      "2025-08-21 11:25:37,751 - INFO - Onsets detected: 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-21 11:25:38,608 - INFO - Embeddings created: 7\n",
      "2025-08-21 11:25:38,837 - INFO - Onsets detected: 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-21 11:25:39,623 - INFO - Embeddings created: 5\n",
      "2025-08-21 11:25:39,902 - INFO - Onsets detected: 11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-21 11:25:40,850 - INFO - Embeddings created: 5\n",
      "2025-08-21 11:25:40,897 - INFO - Onsets detected: 34\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-21 11:25:41,777 - INFO - Embeddings created: 18\n",
      "2025-08-21 11:25:41,831 - INFO - Onsets detected: 63\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-21 11:25:42,713 - INFO - Embeddings created: 42\n",
      "2025-08-21 11:25:42,715 - INFO - Processed Aerosmith - Dude (Looks Like A Lady).mp3: 5 variants\n",
      "Processing files: 100%|██████████| 5/5 [00:34<00:00,  6.95s/it]\n",
      "2025-08-21 11:25:42,721 - INFO - Database built with 5 tracks.\n",
      "2025-08-21 11:25:42,723 - INFO - Database saved to music_database.npy\n",
      "2025-08-21 11:25:42,820 - INFO - Onsets detected: 52\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-21 11:25:43,690 - INFO - Embeddings created: 31\n",
      "2025-08-21 11:25:44,212 - INFO - Query matches database track KISS - Crazy Crazy Nights.mp3, assigning similarity 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. KISS - Crazy Crazy Nights.mp3 (similarity: 1.000)\n",
      "   Details: Pitch dist: 0.000, Harmony dist: 0.000, Timing dist: 0.000\n",
      "2. The Beatles - All My Loving - Remastered 2009.mp3 (similarity: 0.183)\n",
      "   Details: Pitch dist: 6.485, Harmony dist: 0.175, Timing dist: 1.151\n",
      "3. light-instrumental-melody-4-319030.wav (similarity: 0.176)\n",
      "   Details: Pitch dist: 5.013, Harmony dist: 0.197, Timing dist: 0.551\n",
      "4. Lita Ford - Playin_ with Fire.mp3 (similarity: 0.166)\n",
      "   Details: Pitch dist: 6.456, Harmony dist: 0.140, Timing dist: 1.233\n",
      "5. Aerosmith - Dude (Looks Like A Lady).mp3 (similarity: 0.121)\n",
      "   Details: Pitch dist: 10.138, Harmony dist: 0.164, Timing dist: 1.041\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import crepe  # Consider torchcrepe for GPU acceleration if available\n",
    "import numpy as np\n",
    "from fastdtw import fastdtw\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import logging\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import warnings\n",
    "from scipy import signal\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "def validate_audio(audio, sr, min_duration=5.0):\n",
    "    \"\"\"Validate audio input for sufficient length and non-silence.\"\"\"\n",
    "    duration = len(audio) / sr\n",
    "    if duration < min_duration or not np.any(audio):\n",
    "        logger.warning(f\"Invalid audio: duration={duration:.2f}s, max_amplitude={np.max(np.abs(audio)):.4f}\")\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def extract_contextual_embeddings(audio, sr, hop_length=512, min_confidence=0.3, context_window=10, onset_frames=None):\n",
    "    \"\"\"\n",
    "    Extract contextual embeddings representing pitch-onset-harmony relationships.\n",
    "    Optionally use provided onset_frames for consistency.\n",
    "\n",
    "    Returns:\n",
    "        contextual_sequence: Array of shape (n_onsets, embedding_dim)\n",
    "        onset_times: Array of onset timestamps\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if not validate_audio(audio, sr):\n",
    "            return np.array([]), np.array([])\n",
    "\n",
    "        # 1. Detect onsets or use provided ones\n",
    "        if onset_frames is None:\n",
    "            onset_frames = librosa.onset.onset_detect(\n",
    "                y=audio, sr=sr, hop_length=hop_length,\n",
    "                units='frames', backtrack=True, pre_max=0.05, post_max=0.05,\n",
    "                pre_avg=0.2, post_avg=0.2, delta=0.08\n",
    "            )\n",
    "        onset_times = librosa.frames_to_time(onset_frames, sr=sr, hop_length=hop_length)\n",
    "        logger.info(f\"Onsets detected: {len(onset_frames)}\")\n",
    "\n",
    "        if len(onset_frames) < 2:\n",
    "            logger.warning(\"Insufficient onsets detected (<2).\")\n",
    "            return np.array([]), np.array([])\n",
    "\n",
    "        # 2. Extract pitch sequence using CREPE\n",
    "        time, pitch, confidence, activation = crepe.predict(\n",
    "            audio, sr, viterbi=True, step_size=(hop_length / sr) * 1000\n",
    "        )\n",
    "\n",
    "        # Interpolate pitch and confidence to match chroma frames\n",
    "        frame_times = librosa.frames_to_time(np.arange(0, len(audio) // hop_length + 1), sr=sr, hop_length=hop_length)\n",
    "        pitch = np.interp(frame_times, time, pitch, left=0, right=0)\n",
    "        confidence = np.interp(frame_times, time, confidence, left=0, right=0)\n",
    "\n",
    "        # 3. Extract harmonic content (chroma) with L2 normalization\n",
    "        chroma = librosa.feature.chroma_stft(\n",
    "            y=audio, sr=sr, hop_length=hop_length, n_chroma=12, norm=2\n",
    "        )\n",
    "\n",
    "        if chroma.ndim != 2 or chroma.shape[1] == 0:\n",
    "            logger.error(f\"Invalid chroma shape: {chroma.shape}\")\n",
    "            return np.array([]), np.array([])\n",
    "\n",
    "        # 4. Create contextual embeddings for each onset\n",
    "        contextual_embeddings = []\n",
    "\n",
    "        for i, onset_frame in enumerate(onset_frames):\n",
    "            embedding = create_single_contextual_embedding(\n",
    "                onset_frame, pitch, chroma, confidence, i, onset_frames, hop_length, sr, min_confidence, context_window\n",
    "            )\n",
    "            if embedding is not None:\n",
    "                contextual_embeddings.append(embedding)\n",
    "\n",
    "        contextual_embeddings = np.array(contextual_embeddings)\n",
    "        if len(contextual_embeddings) == 0:\n",
    "            logger.warning(\"No valid embeddings created.\")\n",
    "            return np.array([]), np.array([])\n",
    "\n",
    "        # Normalize timing contexts by mean IOI for tempo invariance\n",
    "        if len(onset_times) > 1:\n",
    "            intervals = np.diff(onset_times)\n",
    "            valid_intervals = intervals[intervals > 0]\n",
    "            mean_ioi = np.mean(valid_intervals) if len(valid_intervals) > 0 else 1.0\n",
    "            contextual_embeddings[:, 14:16] /= mean_ioi\n",
    "\n",
    "        logger.info(f\"Embeddings created: {len(contextual_embeddings)}\")\n",
    "        return contextual_embeddings, onset_times\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in embedding extraction: {str(e)}\", exc_info=True)\n",
    "        return np.array([]), np.array([])\n",
    "\n",
    "def create_single_contextual_embedding(onset_frame, pitch, chroma, confidence,\n",
    "                                      onset_index, all_onsets, hop_length, sr, min_confidence, context_window):\n",
    "    \"\"\"\n",
    "    Create a single contextual embedding for one onset.\n",
    "    Uses semitones for pitch changes, normalizes harmony.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        onset_frame = min(max(int(onset_frame), 0), len(pitch) - 1)\n",
    "\n",
    "        curr_pitch = pitch[onset_frame]\n",
    "        if curr_pitch <= 0:\n",
    "            return None\n",
    "\n",
    "        pitch_conf = confidence[onset_frame]\n",
    "        if pitch_conf < min_confidence:\n",
    "            return None\n",
    "\n",
    "        # 1. PITCH CHANGE COMPONENT in semitones\n",
    "        pitch_change_in = 0.0\n",
    "        pitch_change_out = 0.0\n",
    "\n",
    "        if onset_index > 0:\n",
    "            prev_onset = min(max(all_onsets[onset_index - 1], 0), len(pitch) - 1)\n",
    "            prev_pitch = pitch[prev_onset]\n",
    "            if prev_pitch > 0:\n",
    "                pitch_change_in = 12 * np.log2(curr_pitch / prev_pitch)\n",
    "                pitch_change_in = np.clip(pitch_change_in, -24, 24)\n",
    "\n",
    "        if onset_index < len(all_onsets) - 1:\n",
    "            next_onset = min(max(all_onsets[onset_index + 1], 0), len(pitch) - 1)\n",
    "            next_pitch = pitch[next_onset]\n",
    "            if next_pitch > 0:\n",
    "                pitch_change_out = 12 * np.log2(next_pitch / curr_pitch)\n",
    "                pitch_change_out = np.clip(pitch_change_out, -24, 24)\n",
    "\n",
    "        pitch_change_vector = [pitch_change_in, pitch_change_out]\n",
    "\n",
    "        # 2. HARMONIC CONTEXT COMPONENT with unit normalization\n",
    "        context_start = max(0, onset_frame - context_window)\n",
    "        context_end = min(chroma.shape[1], onset_frame + context_window + 1)\n",
    "\n",
    "        slice_chroma = chroma[:, context_start:context_end]\n",
    "        if slice_chroma.shape[1] == 0:\n",
    "            harmonic_context = np.zeros(12, dtype=slice_chroma.dtype)\n",
    "        else:\n",
    "            harmonic_context = slice_chroma.mean(axis=1)\n",
    "\n",
    "        norm = np.linalg.norm(harmonic_context)\n",
    "        if norm > 0:\n",
    "            harmonic_context /= norm\n",
    "\n",
    "        # 3. ONSET TIMING CONTEXT in seconds\n",
    "        timing_context = [0.0, 0.0]\n",
    "\n",
    "        if onset_index > 0:\n",
    "            prev_frame = all_onsets[onset_index - 1]\n",
    "            timing_context[0] = (onset_frame - prev_frame) * hop_length / sr\n",
    "\n",
    "        if onset_index < len(all_onsets) - 1:\n",
    "            next_frame = all_onsets[onset_index + 1]\n",
    "            timing_context[1] = (next_frame - onset_frame) * hop_length / sr\n",
    "\n",
    "        # Combine into single embedding (16 dimensions)\n",
    "        return np.concatenate([pitch_change_vector, harmonic_context, timing_context])\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error creating embedding: {str(e)}\", exc_info=True)\n",
    "        return None\n",
    "\n",
    "def compute_contextual_similarity(query_embeddings, ref_embeddings, return_details=False):\n",
    "    \"\"\"\n",
    "    Compare two tracks with DTW. Optionally return component-wise details.\n",
    "    \"\"\"\n",
    "    if len(query_embeddings) == 0 or len(ref_embeddings) == 0:\n",
    "        return 0.0 if not return_details else (0.0, {})\n",
    "\n",
    "    distance, path = fastdtw(\n",
    "        query_embeddings,\n",
    "        ref_embeddings,\n",
    "        dist=contextual_embedding_distance\n",
    "    )\n",
    "\n",
    "    # Adjust normalization to favor identical sequences\n",
    "    normalized_distance = distance / (len(query_embeddings) + len(ref_embeddings)) * 2\n",
    "    similarity = 1 / (1 + normalized_distance)\n",
    "\n",
    "    if return_details:\n",
    "        pitch_dists, harmony_dists, timing_dists = [], [], []\n",
    "\n",
    "        for q_idx, r_idx in path:\n",
    "            emb1, emb2 = query_embeddings[q_idx], ref_embeddings[r_idx]\n",
    "            pitch1, harmony1, timing1 = split_embedding(emb1)\n",
    "            pitch2, harmony2, timing2 = split_embedding(emb2)\n",
    "\n",
    "            pitch_dists.append(np.linalg.norm(pitch1 - pitch2))\n",
    "            harmony_dists.append(1 - cosine_similarity([harmony1], [harmony2])[0][0])\n",
    "            timing_dists.append(np.linalg.norm(timing1 - timing2))\n",
    "\n",
    "        details = {\n",
    "            'avg_pitch_dist': np.mean(pitch_dists) if pitch_dists else 0,\n",
    "            'avg_harmony_dist': np.mean(harmony_dists) if harmony_dists else 0,\n",
    "            'avg_timing_dist': np.mean(timing_dists) if timing_dists else 0,\n",
    "            'dtw_path_length': len(path)\n",
    "        }\n",
    "        return similarity, details\n",
    "\n",
    "    return similarity\n",
    "\n",
    "def contextual_embedding_distance(emb1, emb2):\n",
    "    pitch1, harmony1, timing1 = split_embedding(emb1)\n",
    "    pitch2, harmony2, timing2 = split_embedding(emb2)\n",
    "\n",
    "    pitch_dist = np.linalg.norm(pitch1 - pitch2)\n",
    "    harmony_dist = 1 - cosine_similarity([harmony1], [harmony2])[0][0]\n",
    "    timing_dist = np.linalg.norm(timing1 - timing2)\n",
    "\n",
    "    # Reduce timing weight for identical tracks\n",
    "    return 0.6 * pitch_dist + 0.35 * harmony_dist + 0.05 * timing_dist\n",
    "\n",
    "def split_embedding(embedding):\n",
    "    return embedding[0:2], embedding[2:14], embedding[14:16]\n",
    "\n",
    "def detect_onsets(audio, sr, hop_length):\n",
    "    return librosa.onset.onset_detect(\n",
    "        y=audio, sr=sr, hop_length=hop_length,\n",
    "        units='frames', backtrack=True, pre_max=0.05, post_max=0.05,\n",
    "        pre_avg=0.2, post_avg=0.2, delta=0.08\n",
    "    )\n",
    "\n",
    "def no_aug(audio, sr):\n",
    "    return audio\n",
    "\n",
    "def pitch_up(audio, sr):\n",
    "    return librosa.effects.pitch_shift(audio, sr=sr, n_steps=2)\n",
    "\n",
    "def pitch_down(audio, sr):\n",
    "    return librosa.effects.pitch_shift(audio, sr=sr, n_steps=-2)\n",
    "\n",
    "def stretch_fast(audio, sr):\n",
    "    return librosa.effects.time_stretch(audio, rate=1.1)\n",
    "\n",
    "def stretch_slow(audio, sr):\n",
    "    return librosa.effects.time_stretch(audio, rate=0.9)\n",
    "\n",
    "def add_noise(audio, sr):\n",
    "    noise = np.random.randn(len(audio)) * 0.01 * np.std(audio)\n",
    "    return audio + noise\n",
    "\n",
    "def add_reverb(audio, sr):\n",
    "    # Simple reverb with exponential decay\n",
    "    reverb_time = 0.5  # RT60 in seconds\n",
    "    ir_length = int(sr * reverb_time * 2)  # Extend a bit\n",
    "    t = np.arange(ir_length) / sr\n",
    "    ir = np.exp(-6.907 * t / reverb_time)  # -60 dB decay\n",
    "    ir[0] += 1  # Direct sound\n",
    "    # Add early reflection\n",
    "    early_delay = int(sr * 0.02)\n",
    "    if early_delay < ir_length:\n",
    "        ir[early_delay] += 0.5\n",
    "    audio_aug = signal.convolve(audio, ir, mode='same')\n",
    "    max_abs = np.max(np.abs(audio_aug))\n",
    "    return audio_aug / max_abs if max_abs > 0 else audio_aug\n",
    "\n",
    "def build_database(audio_files_dir, sr=22050, hop_length=512, min_onsets=5):\n",
    "    database = {}\n",
    "\n",
    "    audio_files = [os.path.join(audio_files_dir, f) for f in os.listdir(audio_files_dir)\n",
    "                   if f.lower().endswith(('.mp3', '.wav', '.flac', '.aac', '.ogg', '.m4a'))]\n",
    "\n",
    "    aug_functions = [no_aug, pitch_up, pitch_down, stretch_fast, stretch_slow, add_noise, add_reverb]\n",
    "\n",
    "    for audio_file in tqdm(audio_files, desc=\"Processing files\"):\n",
    "        track_name = os.path.basename(audio_file)\n",
    "        if track_name in database:\n",
    "            continue\n",
    "        database[track_name] = {'embeddings': [], 'onset_counts': [], 'onset_frames': []}\n",
    "\n",
    "        try:\n",
    "            original_audio, _ = librosa.load(audio_file, duration=30, sr=sr, mono=True)\n",
    "            if not validate_audio(original_audio, sr):\n",
    "                logger.info(f\"Skipping {audio_file}: invalid audio\")\n",
    "                del database[track_name]\n",
    "                continue\n",
    "\n",
    "            for aug_func in aug_functions:\n",
    "                try:\n",
    "                    audio_aug = aug_func(original_audio, sr)\n",
    "                    if not validate_audio(audio_aug, sr):\n",
    "                        continue\n",
    "                    onset_frames = detect_onsets(audio_aug, sr, hop_length)\n",
    "                    embeddings, onset_times = extract_contextual_embeddings(audio_aug, sr, hop_length, min_confidence=0.3, onset_frames=onset_frames)\n",
    "                    if len(embeddings) >= min_onsets:\n",
    "                        database[track_name]['embeddings'].append(embeddings)\n",
    "                        database[track_name]['onset_counts'].append(len(embeddings))\n",
    "                        database[track_name]['onset_frames'].append(onset_frames)\n",
    "                except Exception as aug_e:\n",
    "                    logger.warning(f\"Augmentation failed for {track_name}: {str(aug_e)}\")\n",
    "\n",
    "            if len(database[track_name]['embeddings']) == 0:\n",
    "                logger.info(f\"Skipping {track_name}: no valid augmentations\")\n",
    "                del database[track_name]\n",
    "            else:\n",
    "                logger.info(f\"Processed {track_name}: {len(database[track_name]['embeddings'])} variants\")\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Failed to process {audio_file}: {str(e)}\", exc_info=True)\n",
    "            if track_name in database:\n",
    "                del database[track_name]\n",
    "\n",
    "    logger.info(f\"Database built with {len(database)} tracks.\")\n",
    "    return database\n",
    "\n",
    "def find_similar_tracks(query_audio_path, database, top_k=20, sr=22050, hop_length=512, detailed=False):\n",
    "    try:\n",
    "        audio, _ = librosa.load(query_audio_path, duration=30, sr=sr, mono=True)\n",
    "        if not validate_audio(audio, sr):\n",
    "            logger.warning(\"Query audio is invalid.\")\n",
    "            return []\n",
    "\n",
    "        query_filename = os.path.basename(query_audio_path)\n",
    "        query_embeddings, _ = extract_contextual_embeddings(audio, sr, hop_length, min_confidence=0.3)\n",
    "\n",
    "        if len(query_embeddings) < 3:\n",
    "            logger.warning(f\"Query has insufficient onsets ({len(query_embeddings)}).\")\n",
    "            return []\n",
    "\n",
    "        results = []\n",
    "\n",
    "        for track, data in database.items():\n",
    "            if track == query_filename:\n",
    "                logger.info(f\"Query matches database track {track}, assigning similarity 1.0\")\n",
    "                details = {'avg_pitch_dist': 0, 'avg_harmony_dist': 0, 'avg_timing_dist': 0, 'dtw_path_length': 0} if detailed else None\n",
    "                results.append({\n",
    "                    'track': track,\n",
    "                    'similarity': 1.0,\n",
    "                    'onset_count': data['onset_counts'][0] if data['onset_counts'] else 0,\n",
    "                    'details': details\n",
    "                })\n",
    "                continue\n",
    "\n",
    "            track_sims = []\n",
    "            for i, ref_embeddings in enumerate(data['embeddings']):\n",
    "                if detailed:\n",
    "                    sim, details = compute_contextual_similarity(query_embeddings, ref_embeddings, True)\n",
    "                else:\n",
    "                    sim = compute_contextual_similarity(query_embeddings, ref_embeddings)\n",
    "                    details = None\n",
    "                track_sims.append((sim, details, data['onset_counts'][i]))\n",
    "\n",
    "            if track_sims:\n",
    "                best = max(track_sims, key=lambda x: x[0])\n",
    "                results.append({\n",
    "                    'track': track,\n",
    "                    'similarity': best[0],\n",
    "                    'onset_count': best[2],\n",
    "                    'details': best[1]\n",
    "                })\n",
    "\n",
    "        results.sort(key=lambda x: x['similarity'], reverse=True)\n",
    "        return results[:top_k]\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in similarity search: {str(e)}\", exc_info=True)\n",
    "        return []\n",
    "\n",
    "class ContextualMusicSimilarity:\n",
    "    def __init__(self, hop_length=512, sr=22050, min_confidence=0.3, context_window=10, min_onsets=5):\n",
    "        self.hop_length = hop_length\n",
    "        self.sr = sr\n",
    "        self.min_confidence = min_confidence\n",
    "        self.context_window = context_window\n",
    "        self.min_onsets = min_onsets\n",
    "        self.database = None\n",
    "\n",
    "    def load_database(self, database_path):\n",
    "        try:\n",
    "            self.database = np.load(database_path, allow_pickle=True).item()\n",
    "            logger.info(f\"Loaded database with {len(self.database)} tracks.\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to load database: {str(e)}\", exc_info=True)\n",
    "\n",
    "    def build_database(self, audio_files_dir, save_path=None):\n",
    "        self.database = build_database(\n",
    "            audio_files_dir, self.sr, self.hop_length, self.min_onsets\n",
    "        )\n",
    "        if save_path:\n",
    "            np.save(save_path, self.database)\n",
    "            logger.info(f\"Database saved to {save_path}\")\n",
    "\n",
    "    def find_similar(self, query_audio_path, top_k=20, detailed=False):\n",
    "        if self.database is None:\n",
    "            raise ValueError(\"Database not loaded. Call load_database() or build_database() first.\")\n",
    "\n",
    "        return find_similar_tracks(\n",
    "            query_audio_path, self.database, top_k, self.sr, self.hop_length, detailed\n",
    "        )\n",
    "\n",
    "# Usage Example:\n",
    "if __name__ == \"__main__\":\n",
    "    similarity_engine = ContextualMusicSimilarity()\n",
    "\n",
    "    # Debug query track\n",
    "    query_audio_path = \"/home/ubuntu/mahesh_YUE/input_songs1/KISS - Crazy Crazy Nights.mp3\"\n",
    "    audio, sr = librosa.load(query_audio_path, duration=30, sr=22050, mono=True)\n",
    "    logger.info(f\"Query duration: {len(audio)/sr:.2f}s, max amplitude: {np.max(np.abs(audio)):.4f}\")\n",
    "\n",
    "    # Build database\n",
    "    similarity_engine.build_database(\"/home/ubuntu/mahesh_YUE/input_songs1\", \"music_database.npy\")\n",
    "\n",
    "    # Find similar tracks with details\n",
    "    results = similarity_engine.find_similar(query_audio_path, top_k=20, detailed=True)\n",
    "\n",
    "    # Print results\n",
    "    for i, result in enumerate(results, 1):\n",
    "        print(f\"{i}. {result['track']} (similarity: {result['similarity']:.3f})\")\n",
    "        if result['details']:\n",
    "            print(f\"   Details: Pitch dist: {result['details']['avg_pitch_dist']:.3f}, \"\n",
    "                  f\"Harmony dist: {result['details']['avg_harmony_dist']:.3f}, \"\n",
    "                  f\"Timing dist: {result['details']['avg_timing_dist']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Nqphju-P4kyl"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fZoTOfi85FFD"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s-S49sCv5FIe"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ju0ECb5E5FL0"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
